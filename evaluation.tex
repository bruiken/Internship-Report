\chapter{Evaluation}\label{ch:evaluation}
This chapter covers the evaluation of the implemented operator. The quantifiable
results are minimal, because of the problems of the approach mentioned previously.
This chapter first starts with some notes on the generation of test data, and the
difficulties that come with it. We then briefly give some results on the time
taken by our implemented \emph{fix} operator.

\section{(Generation of) Test Data}\label{sec:testdata}
After the discovery of the aforementioned problems with the implementation of the
\emph{fix} operator in the current version of aCaPulCO, it should be clear that
we cannot test the large feature models that were used to evaluate the tool without
the \emph{fix} operator. These large feature models such as \emph{Linux} and
\emph{Automotive} (which are common feature models used to benchmark tools) are
simply too large to be able to generate all the CPCOs. For the small feature models,
we already have several other tools that can handle them. This means that we
need to get ahold of more input data.

To be able to control certain parameters in feature model generation, we could use
a tool such as BeTTy~\cite{segura2012betty} (BEnchmarking and TesTing on the analYsis
of feature models). It is a highly configurable tool that can be used to generate
(extended) feature models, it is easy to use parallel to aCaPulCO, as it is also
written in Java.

Because we want to benchmark specifically our \emph{fix} operator, we want to
generate feature models with many cross-tree constraints. Specifically, we want to
generate \emph{complex} cross-tree constraints. It should be clear that a feature
model with many cross-tree constraints would also need many features. If we have
a limited number of features, it is difficult to generate cross-tree constraints
that do not invalidate other constraints. We also do not want cross-tree constraints
to create dead features (features that can never be active), or false optional 
features (features that should be optional but are made mandatory because of
added constraints). For a tool such as BeTTy to create feature models that adhere
to these requirements, as well as a large number of cross-tree constraints, it needs
to generate large feature models with thousands of features. This brings us back to
our initial problem, where we did not want such large models, as it is not feasible
to generate all the CPCOs for them.

Apart from the difficulty of generating valid cross-tree constraints, it should
also be noted that a tool such as BeTTy can only generate simple constraints: it
is limited to creating \emph{requires} and \emph{excludes} relationships. For us,
this is not useful as aCaPulCO already can deal with these.
What we can do to prevent this, is to generate simple constraints and mark them
as complex constraints. With this approach, we do not solve the problem of the
generation that we mentioned previously.

To create the models that are used for our results, we let BeTTy generate models
with an increasing number of constraints. We limited the number of features to
a hundred, to prevent not being able to finish CPCO generation. The number of
complex constraints was set between 10\% and 45\% (in terms of the number of features).
BeTTy generates feature models that are not directly supported by aCaPulCO, because
of formatting differences, to solve this, they can first be opened in FeatureIDE~\footnote{\url{https://www.featureide.de/}}.
We already mentioned that BeTTy generates constraints that will result in dead
or false-optional features, these problems were solved by hand, also in FeatureIDE.

\section{Results}\label{sec:results}
In the previous sections, we realised that our \emph{fix} operator is not a good
fit for the current version of aCaPulCO, as it requires all the CPCO rules to be
generated, while the other operators in aCaPulCO do not have this requirement.
The smaller feature models that were benchmarked in the previous work on aCaPulCO
do not have to be benchmarked again with the \emph{fix} operator enabled, as these
small feature models do not contain any complex cross-tree constraints at all. That
would mean that our new operator does not get any work at all.

As we mentioned before, we did generate a number of smaller feature models containing
complex constraints. The results from these feature models can be found in Table~\ref{tab:results}.
In the table, we can see for each model: the number of features, the number of constraints
(\emph{S} for simple- and \emph{C} for complex constraints). Then we see the runtime
comparison between not having the fix operator and the runtime including the constraints
and fix operator. In the last column we can see the number of times a fix had to be
applied by the operator. The results were generated by running each model ten times, and taking the median of
the runtimes and application count.

The number of features is increased from what we described earlier (118 instead of 100),
this is because of the format change we had to apply, this increased the number of features
by creating separate features for group constraints. The simple constraints are all
non cross-tree-constraints: they make up the group constaints and mandatory feature
constarints. It should also be noted that the number of complex constraints is significantly
lower than expected. In the ideal case, this number should match the number in the model
name. The decrease is explained by the fact that we had to remove constraints manually
to fix inconsistencies created by them (they created false-optional or dead features).

The difference in runtime the fix operator brings is about a 10\% increase. The number
of times a fix had to be applied does not seem to bring a significant change to the
increase in runtime. The number of times the fix operator had to be applied does not
seem to corrolate strongly with the number of complex constraints in a model. The
seemingly random differences in both the runtime and fix count can be explained by both
the randomness of the algorithm and the fact that we are working with relatively small
models.

\begin{landscape}
\begin{table}[H]
    \centering
    \caption{Table showing the results of the feature models generated by BeTTy}
    \label{tab:results}
    \begin{tabular}{l|lll|ll|l}
        Model & \# Features & \# Constraints (S) & \# Constraints (C) & Runtime (no fix) & Runtime (with fix) & Fix count \\ \hline \hline
        Model10 & 118 & 201 & 5 & 197ms & 216ms & 142 \\
        model15 & 118 & 200 & 10 & 183ms & 196ms & 110 \\
        model20 & 118 & 200 & 13 & 186ms & 203ms & 127 \\
        model25 & 118 & 200 & 16 & 185ms & 202ms & 169 \\ 
        model35 & 118 & 200 & 23 & 191ms & 217ms & 284 \\
        model40 & 118 & 200 & 25 & 187ms & 215ms & 181 \\ 
        model45 & 118 & 200 & 28 & 199ms & 225ms & 230 \\
    \end{tabular}
\end{table}
\end{landscape}
